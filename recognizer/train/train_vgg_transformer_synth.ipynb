{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:33.511002Z","iopub.status.busy":"2021-03-09T09:44:33.510332Z","iopub.status.idle":"2021-03-09T09:44:33.513336Z","shell.execute_reply":"2021-03-09T09:44:33.512859Z"},"papermill":{"duration":0.022561,"end_time":"2021-03-09T09:44:33.513503","exception":false,"start_time":"2021-03-09T09:44:33.490942","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import os, sys, random, gc\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","sys.path.append('../')\n","\n","from playdict_ocr.tokenization import TokenizerNAT\n","from datasets import PartitionedTrainDataset, TrainDataset, TestDataset"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<PAD><PAD_1><PAD_2>ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz~$%&@0123456789* -([)]\"!,.:;?'"]},"metadata":{},"execution_count":2}],"source":["''.join(TokenizerNAT().i2w)"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:47.311836Z","iopub.status.busy":"2021-03-09T09:44:47.311114Z","iopub.status.idle":"2021-03-09T09:44:47.314953Z","shell.execute_reply":"2021-03-09T09:44:47.31454Z"},"papermill":{"duration":0.027167,"end_time":"2021-03-09T09:44:47.315067","exception":false,"start_time":"2021-03-09T09:44:47.2879","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["class CFG:\n","    max_dec_len=25\n","    size=(144, 32)\n","    epochs, batch_size = 2, 256\n","    max_grad_norm=4\n","    encoder_dim, decoder_dim = 192, 256\n","    use_ctc = False\n","    num_pixels = 36\n","\n","if CFG.use_ctc:\n","    CFG.max_dec_len *= 2\n","\n","tokenizer = TokenizerNAT()"],"execution_count":3,"outputs":[]},{"metadata":{"papermill":{"duration":0.022092,"end_time":"2021-03-09T09:44:52.71725","exception":false,"start_time":"2021-03-09T09:44:52.695158","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# MODEL"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:52.768841Z","iopub.status.busy":"2021-03-09T09:44:52.768043Z","iopub.status.idle":"2021-03-09T09:44:52.77223Z","shell.execute_reply":"2021-03-09T09:44:52.77174Z"},"papermill":{"duration":0.033392,"end_time":"2021-03-09T09:44:52.772345","exception":false,"start_time":"2021-03-09T09:44:52.738953","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import keras4torch as k4t\n","from models import EncoderDecoderModel\n","\n","from encoders.repvgg import RepVGG\n","from decoders.nat import NATDecoder\n","\n","encoder = RepVGG(\n","        num_blocks=[2, 4, 6],\n","        width_multiplier=[0.75, 0.75, 0.75],\n","        use_se=False, in_channels=1, output_channels=CFG.encoder_dim)\n","\n","decoder = NATDecoder(encoder_dim=CFG.encoder_dim,\n","                    decoder_dim=CFG.decoder_dim,\n","                    vocab_size=tokenizer.vocab_size,\n","                    max_dec_len=CFG.max_dec_len,\n","                    num_pixels=CFG.num_pixels)\n","\n","model = EncoderDecoderModel(encoder, decoder)"],"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["====================================================================================================\n","Layer (type:depth-idx)                             Output Shape              Param #\n","====================================================================================================\n","├─RepVGG: 1-1                                      [8, 192, 2, 36]           --\n","|    └─RepVGGBlock: 2-1                            [8, 48, 16, 72]           --\n","|    |    └─Sequential: 3-1                        [8, 48, 16, 72]           528\n","|    |    └─Sequential: 3-2                        [8, 48, 16, 72]           144\n","|    |    └─Identity: 3-3                          [8, 48, 16, 72]           --\n","|    |    └─ReLU: 3-4                              [8, 48, 16, 72]           --\n","|    └─Sequential: 2-2                             [8, 48, 8, 36]            --\n","|    |    └─RepVGGBlock: 3-5                       [8, 48, 8, 36]            23,232\n","|    |    └─RepVGGBlock: 3-6                       [8, 48, 8, 36]            23,328\n","|    └─Sequential: 2-3                             [8, 96, 4, 36]            --\n","|    |    └─RepVGGBlock: 3-7                       [8, 96, 4, 36]            46,464\n","|    |    └─RepVGGBlock: 3-8                       [8, 96, 4, 36]            92,736\n","|    |    └─RepVGGBlock: 3-9                       [8, 96, 4, 36]            92,736\n","|    |    └─RepVGGBlock: 3-10                      [8, 96, 4, 36]            92,736\n","|    └─Sequential: 2-4                             [8, 192, 2, 36]           --\n","|    |    └─RepVGGBlock: 3-11                      [8, 192, 2, 36]           185,088\n","|    |    └─RepVGGBlock: 3-12                      [8, 192, 2, 36]           369,792\n","|    |    └─RepVGGBlock: 3-13                      [8, 192, 2, 36]           369,792\n","|    |    └─RepVGGBlock: 3-14                      [8, 192, 2, 36]           369,792\n","|    |    └─RepVGGBlock: 3-15                      [8, 192, 2, 36]           369,792\n","|    |    └─RepVGGBlock: 3-16                      [8, 192, 2, 36]           369,792\n","|    └─Sequential: 2-5                             [8, 192, 2, 36]           --\n","|    |    └─RepVGGBlock: 3-17                      [8, 192, 2, 36]           369,792\n","├─NATDecoder: 1-2                                  [8, 25, 84]               --\n","|    └─Linear: 2-6                                 [8, 36, 256]              49,408\n","|    └─Linear: 2-7                                 [8, 256, 25]              925\n","|    └─Sequential: 2-8                             [8, 25, 256]              --\n","|    |    └─TransformerEncoderLayer2: 3-18         [8, 25, 256]              527,104\n","|    |    └─TransformerEncoderLayer2: 3-19         [8, 25, 256]              527,104\n","|    |    └─TransformerEncoderLayer2: 3-20         [8, 25, 256]              527,104\n","|    └─Linear: 2-9                                 [8, 25, 84]               21,588\n","====================================================================================================\n","Total params: 4,428,977\n","Trainable params: 4,428,977\n","Non-trainable params: 0\n","Total mult-adds (M): 18.08\n","====================================================================================================\n","Encoder: 2775744\n","Decoder: 1653233\n"]}],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_optimizer import AdaBelief\n","\n","class CombinedOpt(torch.optim.Optimizer):\n","    def __init__(self, model):\n","        super().__init__(model.parameters(), {'lr': float('-inf')})\n","        self.encoder_opt = AdaBelief(\n","            model.encoder.parameters(), lr=2e-3*0.3, weight_decay=1e-5)\n","        self.decoder_opt = torch.optim.Adam(\n","            model.decoder.parameters(), lr=1e-3*0.3, weight_decay=1e-5)\n","\n","    def step(self):\n","        self.encoder_opt.step()\n","        self.decoder_opt.step()\n","\n","opt = CombinedOpt(model)\n","\n","def ce_loss(y_pred, y_true):\n","    y_pred = y_pred.reshape(-1, tokenizer.vocab_size)\n","    y_true = y_true.reshape(-1)\n","    return F.cross_entropy(y_pred, y_true)\n","\n","def acc(y_pred, y_true):\n","    y_pred = y_pred.argmax(-1).cpu().numpy()\n","    y_true = y_true.cpu().numpy()\n","\n","    y_ = [(tokenizer.indices_to_string(i) == tokenizer.indices_to_string(j))\n","            for i,j in zip(y_pred, y_true)]\n","    return torch.tensor(y_, dtype=float).mean()\n","\n","class MyLoopConfig(k4t.configs.TrainerLoopConfig):\n","    def process_batch(self, batch):\n","        *x_batch, y_batch = batch\n","        self.target_lengths = x_batch[1]\n","        return x_batch[:1], y_batch\n","\n","    def prepare_for_optimizer_step(self, model):\n","        torch.nn.utils.clip_grad_norm_(model.model.encoder.parameters(), CFG.max_grad_norm)\n","        torch.nn.utils.clip_grad_norm_(model.model.decoder.parameters(), CFG.max_grad_norm)\n","\n","    def ctc_loss(self, y_pred, y_true):\n","        batch_size = y_pred.size(0)\n","        y_pred = torch.log_softmax(y_pred, dim=-1)      # [bs, max_dec_len*2, vocab_size]\n","        y_pred = y_pred.transpose(0, 1)                 # [max_dec_len*2, bs, vocab_size]\n","        return F.ctc_loss(y_pred, y_true,\n","            input_lengths=torch.full([batch_size], CFG.max_dec_len), target_lengths=self.target_lengths)\n","\n","    def ctc_acc(self, y_pred, y_true):\n","        y_pred = y_pred.argmax(-1).cpu().numpy()\n","        y_true = y_true.cpu().numpy()\n","\n","        y_ = [(tokenizer.indices_to_string_ctc(i) == tokenizer.indices_to_string(j))\n","                for i,j in zip(y_pred, y_true)]\n","\n","        return torch.tensor(y_, dtype=float).mean()\n","\n","model = k4t.Model(model)\n","\n","model.build([1, 32, 144])\n","model.summary()\n","\n","loop = MyLoopConfig()\n","\n","if CFG.use_ctc:\n","    model.compile(optimizer=opt, loss=loop.ctc_loss, metrics=[loop.ctc_acc], loop_config=loop, disable_val_loss=False)\n","else:\n","    model.compile(optimizer=opt, loss=ce_loss, metrics=[acc], loop_config=loop, disable_val_loss=False)\n","\n","model.model.print_params()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["file_list = [f\"../preprocessed/synth_{i}.pkl\" for i in range(2)]\n","cnt_list = [2000000] * 2\n","\n","val_data = pd.read_pickle(\"../preprocessed/val_data.pkl\")\n","\n","train_set = PartitionedTrainDataset(file_list, cnt_list, CFG.max_dec_len, tokenizer, CFG.size)\n","val_set = TrainDataset(val_data, CFG.max_dec_len, tokenizer, CFG.size)"]},{"metadata":{"papermill":{"duration":0.021011,"end_time":"2021-03-09T09:44:58.676694","exception":false,"start_time":"2021-03-09T09:44:58.655683","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# Train loop"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["model.load_weights('saved_model/best_pretrain.pt')"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:58.736334Z","iopub.status.busy":"2021-03-09T09:44:58.735541Z","iopub.status.idle":"2021-03-09T09:44:58.738849Z","shell.execute_reply":"2021-03-09T09:44:58.738363Z"},"papermill":{"duration":0.041299,"end_time":"2021-03-09T09:44:58.739015","exception":false,"start_time":"2021-03-09T09:44:58.697716","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from keras4torch.callbacks import LRScheduler\n","from torch.optim.lr_scheduler import MultiStepLR\n","from keras4torch.utils.data import RestrictedRandomSampler\n","from keras4torch.callbacks import ModelCheckpoint\n","\n","torch.backends.cudnn.benchmark = True\n","\n","scheduler_1 = LRScheduler(MultiStepLR(opt.encoder_opt, [1, 2], 0.3))\n","scheduler_2 = LRScheduler(MultiStepLR(opt.decoder_opt, [1, 2], 0.3))\n","\n","model.fit(train_set,\n","            validation_data=val_set,\n","            epochs=CFG.epochs,\n","            batch_size=CFG.batch_size,\n","            validation_batch_size=CFG.batch_size*2,\n","            sampler=RestrictedRandomSampler(cnt_list),\n","            callbacks=[scheduler_1, scheduler_2, ModelCheckpoint('saved_model/best.pt', monitor='val_acc')]\n",")"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 4000000 samples, validate on 802733 samples:\n","Epoch 1/2\n","15625/15625 - 2417s - loss: 0.0627 - acc: 0.7651 - val_loss: 0.4460 - val_acc: 0.4599 - lr: -inf\n","Epoch 2/2\n","15625/15625 - 2407s - loss: 0.0387 - acc: 0.8369 - val_loss: 0.4723 - val_acc: 0.4659 - lr: -inf\n"]},{"output_type":"execute_result","data":{"text/plain":["       loss       acc  val_loss   val_acc   lr\n","1  0.062697  0.765091  0.445976  0.459850 -inf\n","2  0.038664  0.836902  0.472305  0.465948 -inf"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>acc</th>\n      <th>val_loss</th>\n      <th>val_acc</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.062697</td>\n      <td>0.765091</td>\n      <td>0.445976</td>\n      <td>0.459850</td>\n      <td>-inf</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.038664</td>\n      <td>0.836902</td>\n      <td>0.472305</td>\n      <td>0.465948</td>\n      <td>-inf</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["model.load_weights('saved_model/best.pt')\n","\n","model.model.deploy()"]},{"cell_type":"code","execution_count":10,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stdout","text":["s=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%254)\n  %258 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%225)\n  %259 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%255)\n  %260 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%256)\n  %261 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%257, %258, %259, %260)\n  %262 : Float(1, 25, 8, 32, strides=[6400, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%253, %261) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %263 : Float(1, 8, 25, 32, strides=[6400, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%262) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %264 : Float(1, 8, 32, 25, strides=[6400, 32, 1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%250) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %265 : Float(1, 8, 25, 25, strides=[5000, 625, 25, 1], requires_grad=1, device=cpu) = onnx::MatMul(%238, %264) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %266 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n  %267 : Float(1, 8, 25, 25, strides=[5000, 625, 25, 1], requires_grad=1, device=cpu) = onnx::Mul(%265, %266)\n  %268 : Float(1, 8, 25, 25, strides=[5000, 625, 25, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%267) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:65:0\n  %269 : Float(1, 8, 25, 32, strides=[6400, 800, 32, 1], requires_grad=1, device=cpu) = onnx::MatMul(%268, %263) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:68:0\n  %270 : Float(1, 25, 8, 32, strides=[6400, 32, 800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%269) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:38:0\n  %271 : Long(4, strides=[1], device=cpu) = onnx::Shape(%270)\n  %272 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %273 : Long(device=cpu) = onnx::Gather[axis=0](%271, %272) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %274 : Long(4, strides=[1], device=cpu) = onnx::Shape(%270)\n  %275 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %276 : Long(device=cpu) = onnx::Gather[axis=0](%274, %275) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %277 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %278 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%273)\n  %279 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%276)\n  %280 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%277)\n  %281 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%278, %279, %280)\n  %282 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape(%270, %281) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %283 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.1.attn.final_fc.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %284 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%282, %283) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %285 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%284, %decoder.transformer.1.attn.final_fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %286 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%285, %222) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %287 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%286)\n  %288 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Sub(%286, %287)\n  %289 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %290 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Pow(%288, %289)\n  %291 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%290)\n  %292 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %293 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Add(%291, %292)\n  %294 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Sqrt(%293)\n  %295 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Div(%288, %294)\n  %296 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Mul(%295, %decoder.transformer.1.skip_c_0.ln.weight)\n  %297 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%296, %decoder.transformer.1.skip_c_0.ln.bias)\n  %298 : Float(256, 512, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.1.ffn.0.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %299 : Float(1, 25, 512, strides=[12800, 512, 1], requires_grad=1, device=cpu) = onnx::MatMul(%297, %298) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %300 : Float(1, 25, 512, strides=[12800, 512, 1], requires_grad=1, device=cpu) = onnx::Add(%299, %decoder.transformer.1.ffn.0.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %301 : Float(1, 25, 512, strides=[12800, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%300) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1206:0\n  %302 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.1.ffn.2.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %303 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%301, %302) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %304 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%303, %decoder.transformer.1.ffn.2.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %305 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%304, %297) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %306 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%305)\n  %307 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Sub(%305, %306)\n  %308 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %309 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Pow(%307, %308)\n  %310 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%309)\n  %311 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %312 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Add(%310, %311)\n  %313 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Sqrt(%312)\n  %314 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Div(%307, %313)\n  %315 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Mul(%314, %decoder.transformer.1.skip_c_1.ln.weight)\n  %316 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%315, %decoder.transformer.1.skip_c_1.ln.bias)\n  %317 : Long(3, strides=[1], device=cpu) = onnx::Shape(%316)\n  %318 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %319 : Long(device=cpu) = onnx::Gather[axis=0](%317, %318) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:28:0\n  %320 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.2.attn.WQ.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %321 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%316, %320) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %322 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%321, %decoder.transformer.2.attn.WQ.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %323 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %324 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n  %325 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={32}]()\n  %326 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%323)\n  %327 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%319)\n  %328 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%324)\n  %329 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%325)\n  %330 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%326, %327, %328, %329)\n  %331 : Float(1, 25, 8, 32, strides=[6400, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%322, %330) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:29:0\n  %332 : Float(1, 8, 25, 32, strides=[6400, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%331) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:29:0\n  %333 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.2.attn.WK.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %334 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%316, %333) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %335 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%334, %decoder.transformer.2.attn.WK.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %336 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %337 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n  %338 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={32}]()\n  %339 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%336)\n  %340 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%319)\n  %341 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%337)\n  %342 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%338)\n  %343 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%339, %340, %341, %342)\n  %344 : Float(1, 25, 8, 32, strides=[6400, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%335, %343) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:30:0\n  %345 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.2.attn.WV.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %346 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%316, %345) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %347 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%346, %decoder.transformer.2.attn.WV.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %348 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %349 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n  %350 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={32}]()\n  %351 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%348)\n  %352 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%319)\n  %353 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%349)\n  %354 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%350)\n  %355 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%351, %352, %353, %354)\n  %356 : Float(1, 25, 8, 32, strides=[6400, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%347, %355) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %357 : Float(1, 8, 25, 32, strides=[6400, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%356) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %358 : Float(1, 8, 32, 25, strides=[6400, 32, 1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%344) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %359 : Float(1, 8, 25, 25, strides=[5000, 625, 25, 1], requires_grad=1, device=cpu) = onnx::MatMul(%332, %358) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %360 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n  %361 : Float(1, 8, 25, 25, strides=[5000, 625, 25, 1], requires_grad=1, device=cpu) = onnx::Mul(%359, %360)\n  %362 : Float(1, 8, 25, 25, strides=[5000, 625, 25, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%361) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:65:0\n  %363 : Float(1, 8, 25, 32, strides=[6400, 800, 32, 1], requires_grad=1, device=cpu) = onnx::MatMul(%362, %357) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:68:0\n  %364 : Float(1, 25, 8, 32, strides=[6400, 32, 800, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%363) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:38:0\n  %365 : Long(4, strides=[1], device=cpu) = onnx::Shape(%364)\n  %366 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %367 : Long(device=cpu) = onnx::Gather[axis=0](%365, %366) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %368 : Long(4, strides=[1], device=cpu) = onnx::Shape(%364)\n  %369 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %370 : Long(device=cpu) = onnx::Gather[axis=0](%368, %369) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %371 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %372 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%367)\n  %373 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%370)\n  %374 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%371)\n  %375 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%372, %373, %374)\n  %376 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape(%364, %375) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %377 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.2.attn.final_fc.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %378 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%376, %377) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %379 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%378, %decoder.transformer.2.attn.final_fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %380 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%379, %316) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %381 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%380)\n  %382 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Sub(%380, %381)\n  %383 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %384 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Pow(%382, %383)\n  %385 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%384)\n  %386 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %387 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Add(%385, %386)\n  %388 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Sqrt(%387)\n  %389 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Div(%382, %388)\n  %390 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Mul(%389, %decoder.transformer.2.skip_c_0.ln.weight)\n  %391 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%390, %decoder.transformer.2.skip_c_0.ln.bias)\n  %392 : Float(256, 512, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.2.ffn.0.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %393 : Float(1, 25, 512, strides=[12800, 512, 1], requires_grad=1, device=cpu) = onnx::MatMul(%391, %392) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %394 : Float(1, 25, 512, strides=[12800, 512, 1], requires_grad=1, device=cpu) = onnx::Add(%393, %decoder.transformer.2.ffn.0.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %395 : Float(1, 25, 512, strides=[12800, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%394) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1206:0\n  %396 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.transformer.2.ffn.2.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %397 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%395, %396) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %398 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%397, %decoder.transformer.2.ffn.2.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %399 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%398, %391) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %400 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%399)\n  %401 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Sub(%399, %400)\n  %402 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %403 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Pow(%401, %402)\n  %404 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%403)\n  %405 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %406 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Add(%404, %405)\n  %407 : Float(1, 25, 1, strides=[25, 1, 1], device=cpu) = onnx::Sqrt(%406)\n  %408 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Div(%401, %407)\n  %409 : Float(1, 25, 256, strides=[6400, 256, 1], device=cpu) = onnx::Mul(%408, %decoder.transformer.2.skip_c_1.ln.weight)\n  %410 : Float(1, 25, 256, strides=[6400, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%409, %decoder.transformer.2.skip_c_1.ln.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:2205:0\n  %411 : Float(256, 84, strides=[1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.fc.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %412 : Float(1, 25, 84, strides=[2100, 84, 1], requires_grad=1, device=cpu) = onnx::MatMul(%410, %411) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %413 : Float(1, 25, 84, strides=[2100, 84, 1], requires_grad=1, device=cpu) = onnx::Add(%412, %decoder.fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %y : Long(1, 25, strides=[25, 1], requires_grad=0, device=cpu) = onnx::ArgMax[axis=-1, keepdims=0](%413) # g:\\playdict\\recognizer\\train\\models.py:39:0\n  return (%y)\n\n"]}],"source":["_ = torch.onnx.export(model.model.cpu(),\n","    train_set[0][0].unsqueeze_(0), \"saved_model/vgg_transformer.onnx\", verbose=True, opset_version=11, input_names=['x'], output_names=['y'], do_constant_folding=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"python385jvsc74a57bd069ae1faf8d071295817930cd4dd112d51035d617709be1afa53f8ae3e70204c7","display_name":"Python 3.8.5 64-bit ('data_science': conda)"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.5","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}