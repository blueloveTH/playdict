{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:33.511002Z","iopub.status.busy":"2021-03-09T09:44:33.510332Z","iopub.status.idle":"2021-03-09T09:44:33.513336Z","shell.execute_reply":"2021-03-09T09:44:33.512859Z"},"papermill":{"duration":0.022561,"end_time":"2021-03-09T09:44:33.513503","exception":false,"start_time":"2021-03-09T09:44:33.490942","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import os, sys, random, gc\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","sys.path.append('../')\n","\n","from playdict_ocr.tokenization import TokenizerNAT\n","from datasets import PartitionedTrainDataset, TrainDataset, TestDataset"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<PAD><PAD_1><PAD_2>ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz~$%&@0123456789* -([)]\"!,.:;?'"]},"metadata":{},"execution_count":2}],"source":["''.join(TokenizerNAT().i2w)"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:47.311836Z","iopub.status.busy":"2021-03-09T09:44:47.311114Z","iopub.status.idle":"2021-03-09T09:44:47.314953Z","shell.execute_reply":"2021-03-09T09:44:47.31454Z"},"papermill":{"duration":0.027167,"end_time":"2021-03-09T09:44:47.315067","exception":false,"start_time":"2021-03-09T09:44:47.2879","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["class CFG:\n","    max_dec_len=25\n","    size=(144, 32)\n","    epochs, batch_size = 1, 256\n","    max_grad_norm=4\n","    encoder_dim, decoder_dim = 192, 256\n","    use_ctc = True\n","    num_pixels = 36\n","\n","if CFG.use_ctc:\n","    CFG.max_dec_len *= 2\n","\n","tokenizer = TokenizerNAT()"],"execution_count":3,"outputs":[]},{"metadata":{"papermill":{"duration":0.022092,"end_time":"2021-03-09T09:44:52.71725","exception":false,"start_time":"2021-03-09T09:44:52.695158","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# MODEL"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:52.768841Z","iopub.status.busy":"2021-03-09T09:44:52.768043Z","iopub.status.idle":"2021-03-09T09:44:52.77223Z","shell.execute_reply":"2021-03-09T09:44:52.77174Z"},"papermill":{"duration":0.033392,"end_time":"2021-03-09T09:44:52.772345","exception":false,"start_time":"2021-03-09T09:44:52.738953","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import keras4torch as k4t\n","from models import EncoderDecoderModel\n","\n","from encoders.repvgg import RepVGG\n","from decoders.nat import NATDecoder\n","\n","encoder = RepVGG(\n","        num_blocks=[2, 4, 6],\n","        width_multiplier=[0.75, 0.75, 0.75],\n","        use_se=False, in_channels=1, output_channels=CFG.encoder_dim)\n","\n","encoder.load_state_dict(torch.load('saved_model/repvgg_encoder_pretrain.pt'))\n","\n","decoder = NATDecoder(encoder_dim=CFG.encoder_dim,\n","                    decoder_dim=CFG.decoder_dim,\n","                    vocab_size=tokenizer.vocab_size,\n","                    max_dec_len=CFG.max_dec_len,\n","                    num_pixels=CFG.num_pixels)\n","\n","model = EncoderDecoderModel(encoder, decoder)"],"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\n├─RepVGG: 1-1                                      [8, 192, 2, 36]           --\n|    └─RepVGGBlock: 2-1                            [8, 48, 16, 72]           --\n|    |    └─Sequential: 3-1                        [8, 48, 16, 72]           528\n|    |    └─Sequential: 3-2                        [8, 48, 16, 72]           144\n|    |    └─Identity: 3-3                          [8, 48, 16, 72]           --\n|    |    └─ReLU: 3-4                              [8, 48, 16, 72]           --\n|    └─Sequential: 2-2                             [8, 48, 8, 36]            --\n|    |    └─RepVGGBlock: 3-5                       [8, 48, 8, 36]            23,232\n|    |    └─RepVGGBlock: 3-6                       [8, 48, 8, 36]            23,328\n|    └─Sequential: 2-3                             [8, 96, 4, 36]            --\n|    |    └─RepVGGBlock: 3-7                       [8, 96, 4, 36]            46,464\n|    |    └─RepVGGBlock: 3-8                       [8, 96, 4, 36]            92,736\n|    |    └─RepVGGBlock: 3-9                       [8, 96, 4, 36]            92,736\n|    |    └─RepVGGBlock: 3-10                      [8, 96, 4, 36]            92,736\n|    └─Sequential: 2-4                             [8, 192, 2, 36]           --\n|    |    └─RepVGGBlock: 3-11                      [8, 192, 2, 36]           185,088\n|    |    └─RepVGGBlock: 3-12                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-13                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-14                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-15                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-16                      [8, 192, 2, 36]           369,792\n|    └─Sequential: 2-5                             [8, 192, 2, 36]           --\n|    |    └─RepVGGBlock: 3-17                      [8, 192, 2, 36]           369,792\n├─NATDecoder: 1-2                                  [8, 50, 84]               --\n|    └─Linear: 2-6                                 [8, 36, 256]              49,408\n|    └─Linear: 2-7                                 [8, 256, 50]              1,850\n|    └─Sequential: 2-8                             [8, 50, 256]              --\n|    |    └─TransformerEncoderLayer2: 3-18         [8, 50, 256]              527,104\n|    |    └─TransformerEncoderLayer2: 3-19         [8, 50, 256]              527,104\n|    └─Linear: 2-9                                 [8, 50, 84]               21,588\n====================================================================================================\nTotal params: 3,902,798\nTrainable params: 3,902,798\nNon-trainable params: 0\nTotal mult-adds (M): 15.98\n====================================================================================================\nEncoder: 2775744\nDecoder: 1127054\n"]}],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_optimizer import AdaBelief\n","\n","class CombinedOpt(torch.optim.Optimizer):\n","    def __init__(self, model):\n","        super().__init__(model.parameters(), {'lr': float('-inf')})\n","        self.encoder_opt = AdaBelief(\n","            model.encoder.parameters(), lr=1e-4)\n","        self.decoder_opt = torch.optim.Adam(\n","            model.decoder.parameters(), lr=4e-4, weight_decay=1e-4)\n","\n","    def step(self):\n","        self.encoder_opt.step()\n","        self.decoder_opt.step()\n","\n","opt = CombinedOpt(model)\n","\n","def ce_loss(y_pred, y_true):\n","    y_pred = y_pred.reshape(-1, tokenizer.vocab_size)\n","    y_true = y_true.reshape(-1)\n","    return F.cross_entropy(y_pred, y_true)\n","\n","def acc(y_pred, y_true):\n","    y_pred = y_pred.argmax(-1).cpu().numpy()\n","    y_true = y_true.cpu().numpy()\n","\n","    y_ = [(tokenizer.indices_to_string(i) == tokenizer.indices_to_string(j))\n","            for i,j in zip(y_pred, y_true)]\n","    return torch.tensor(y_, dtype=float).mean()\n","\n","class MyLoopConfig(k4t.configs.TrainerLoopConfig):\n","    def process_batch(self, batch):\n","        *x_batch, y_batch = batch\n","        self.target_lengths = x_batch[1]\n","        return x_batch[:1], y_batch\n","\n","    def prepare_for_optimizer_step(self, model):\n","        torch.nn.utils.clip_grad_norm_(model.model.encoder.parameters(), CFG.max_grad_norm)\n","        torch.nn.utils.clip_grad_norm_(model.model.decoder.parameters(), CFG.max_grad_norm)\n","\n","    def ctc_loss(self, y_pred, y_true):\n","        batch_size = y_pred.size(0)\n","        y_pred = torch.log_softmax(y_pred, dim=-1)      # [bs, max_dec_len*2, vocab_size]\n","        y_pred = y_pred.transpose(0, 1)                 # [max_dec_len*2, bs, vocab_size]\n","        return F.ctc_loss(y_pred, y_true,\n","            input_lengths=torch.full([batch_size], CFG.max_dec_len), target_lengths=self.target_lengths)\n","\n","    def ctc_acc(self, y_pred, y_true):\n","        y_pred = y_pred.argmax(-1).cpu().numpy()\n","        y_true = y_true.cpu().numpy()\n","\n","        y_ = [(tokenizer.indices_to_string_ctc(i) == tokenizer.indices_to_string(j))\n","                for i,j in zip(y_pred, y_true)]\n","\n","        return torch.tensor(y_, dtype=float).mean()\n","\n","model = k4t.Model(model)\n","\n","model.build([1, 32, 144])\n","model.summary()\n","\n","loop = MyLoopConfig()\n","\n","if CFG.use_ctc:\n","    model.compile(optimizer=opt, loss=loop.ctc_loss, metrics=[loop.ctc_acc], loop_config=loop, disable_val_loss=False)\n","else:\n","    model.compile(optimizer=opt, loss=ce_loss, metrics=[acc], loop_config=loop, disable_val_loss=False)\n","\n","model.model.print_params()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["file_list = [f\"../preprocessed/train_data_{i}.pkl\" for i in range(4)]\n","cnt_list = [2000000] * 3 + [1224600]\n","\n","#train_data = pd.read_pickle(\"../preprocessed/synth_0.pkl\")\n","#train_set = TrainDataset(train_data, CFG.max_dec_len, tokenizer, CFG.size)\n","\n","val_data = pd.read_pickle(\"../preprocessed/val_data.pkl\")\n","\n","train_set = PartitionedTrainDataset(file_list, cnt_list, CFG.max_dec_len, tokenizer, CFG.size)\n","val_set = TrainDataset(val_data, CFG.max_dec_len, tokenizer, CFG.size)"]},{"metadata":{"papermill":{"duration":0.021011,"end_time":"2021-03-09T09:44:58.676694","exception":false,"start_time":"2021-03-09T09:44:58.655683","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# Train loop"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:58.736334Z","iopub.status.busy":"2021-03-09T09:44:58.735541Z","iopub.status.idle":"2021-03-09T09:44:58.738849Z","shell.execute_reply":"2021-03-09T09:44:58.738363Z"},"papermill":{"duration":0.041299,"end_time":"2021-03-09T09:44:58.739015","exception":false,"start_time":"2021-03-09T09:44:58.697716","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from keras4torch.callbacks import LRScheduler\n","from torch.optim.lr_scheduler import MultiStepLR\n","from keras4torch.utils.data import RestrictedRandomSampler\n","from keras4torch.callbacks import ModelCheckpoint\n","\n","torch.backends.cudnn.benchmark = True\n","\n","scheduler_1 = LRScheduler(MultiStepLR(opt.encoder_opt, [1, 2], 0.3))\n","scheduler_2 = LRScheduler(MultiStepLR(opt.decoder_opt, [1, 2], 0.3))\n","\n","model.fit(train_set,\n","            validation_data=val_set,\n","            epochs=CFG.epochs,\n","            batch_size=CFG.batch_size,\n","            validation_batch_size=CFG.batch_size*2,\n","            sampler=RestrictedRandomSampler(cnt_list),\n","            callbacks=[scheduler_1, scheduler_2, ModelCheckpoint('saved_model/best.pt', monitor='val_ctc_acc')]\n",")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 7224600 samples, validate on 802733 samples:\n","Epoch 1/1\n","28222/28222 - 4275s - loss: 0.2935 - ctc_acc: 0.7330 - val_loss: 0.2386 - val_ctc_acc: 0.7885 - lr: -inf\n"]},{"output_type":"execute_result","data":{"text/plain":["       loss   ctc_acc  val_loss  val_ctc_acc   lr\n","1  0.293459  0.733003  0.238583     0.788522 -inf"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>ctc_acc</th>\n      <th>val_loss</th>\n      <th>val_ctc_acc</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.293459</td>\n      <td>0.733003</td>\n      <td>0.238583</td>\n      <td>0.788522</td>\n      <td>-inf</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":8,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stdout","text":["02 : Float(1, 192, 2, 36, strides=[13824, 72, 36, 1], requires_grad=0, device=cpu) = onnx::Relu(%101) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1206:0\n  %103 : Float(1, 36, 192, 2, strides=[13824, 1, 72, 36], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 3, 1, 2]](%102) # g:\\playdict\\recognizer\\train\\models.py:33:0\n  %104 : Float(1, 36, 192, strides=[6912, 192, 1], requires_grad=0, device=cpu) = onnx::ReduceMean[axes=[-1], keepdims=0](%103) # g:\\playdict\\recognizer\\train\\models.py:34:0\n  %106 : Float(1, 36, 256, strides=[9216, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%104, %306) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %107 : Float(1, 36, 256, strides=[9216, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%106, %decoder.pre_fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %108 : Float(1, 256, 36, strides=[9216, 1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%107) # g:\\playdict\\recognizer\\train\\decoders\\nat.py:43:0\n  %110 : Float(1, 256, 50, strides=[12800, 50, 1], requires_grad=1, device=cpu) = onnx::MatMul(%108, %307) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %111 : Float(1, 256, 50, strides=[12800, 50, 1], requires_grad=1, device=cpu) = onnx::Add(%110, %decoder.length_fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %112 : Float(1, 50, 256, strides=[12800, 1, 50], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%111)\n  %113 : Long(3, strides=[1], device=cpu) = onnx::Shape(%112)\n  %114 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %115 : Long(device=cpu) = onnx::Gather[axis=0](%113, %114) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:28:0\n  %117 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%112, %308) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %118 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%117, %decoder.transformer.0.attn.WQ.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %123 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%115)\n  %126 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%309, %123, %310, %311)\n  %127 : Float(1, 50, 8, 32, strides=[12800, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%118, %126) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:29:0\n  %128 : Float(1, 8, 50, 32, strides=[12800, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%127) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:29:0\n  %130 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%112, %312) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %131 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%130, %decoder.transformer.0.attn.WK.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %136 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%115)\n  %139 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%313, %136, %314, %315)\n  %140 : Float(1, 50, 8, 32, strides=[12800, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%131, %139) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:30:0\n  %142 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%112, %316) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %143 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%142, %decoder.transformer.0.attn.WV.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %148 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%115)\n  %151 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%317, %148, %318, %319)\n  %152 : Float(1, 50, 8, 32, strides=[12800, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%143, %151) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %153 : Float(1, 8, 50, 32, strides=[12800, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%152) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %154 : Float(1, 8, 32, 50, strides=[12800, 32, 1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%140) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %155 : Float(1, 8, 50, 50, strides=[20000, 2500, 50, 1], requires_grad=1, device=cpu) = onnx::MatMul(%128, %154) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %156 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n  %157 : Float(1, 8, 50, 50, strides=[20000, 2500, 50, 1], requires_grad=1, device=cpu) = onnx::Mul(%155, %156)\n  %158 : Float(1, 8, 50, 50, strides=[20000, 2500, 50, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%157) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:65:0\n  %159 : Float(1, 8, 50, 32, strides=[12800, 1600, 32, 1], requires_grad=1, device=cpu) = onnx::MatMul(%158, %153) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:68:0\n  %160 : Float(1, 50, 8, 32, strides=[12800, 32, 1600, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%159) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:38:0\n  %161 : Long(4, strides=[1], device=cpu) = onnx::Shape(%160)\n  %162 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %163 : Long(device=cpu) = onnx::Gather[axis=0](%161, %162) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %164 : Long(4, strides=[1], device=cpu) = onnx::Shape(%160)\n  %165 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %166 : Long(device=cpu) = onnx::Gather[axis=0](%164, %165) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %168 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%163)\n  %169 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%166)\n  %171 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%168, %169, %320)\n  %172 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape(%160, %171) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %174 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%172, %321) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %175 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%174, %decoder.transformer.0.attn.final_fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %176 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%175, %112) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %177 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%176)\n  %178 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Sub(%176, %177)\n  %179 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %180 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Pow(%178, %179)\n  %181 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%180)\n  %182 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %183 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Add(%181, %182)\n  %184 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Sqrt(%183)\n  %185 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Div(%178, %184)\n  %186 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Mul(%185, %decoder.transformer.0.skip_c_0.ln.weight)\n  %187 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%186, %decoder.transformer.0.skip_c_0.ln.bias)\n  %189 : Float(1, 50, 512, strides=[25600, 512, 1], requires_grad=1, device=cpu) = onnx::MatMul(%187, %322) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %190 : Float(1, 50, 512, strides=[25600, 512, 1], requires_grad=1, device=cpu) = onnx::Add(%189, %decoder.transformer.0.ffn.0.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %191 : Float(1, 50, 512, strides=[25600, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%190) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1206:0\n  %193 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%191, %323) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %194 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%193, %decoder.transformer.0.ffn.2.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %195 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%194, %187) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %196 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%195)\n  %197 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Sub(%195, %196)\n  %198 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %199 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Pow(%197, %198)\n  %200 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%199)\n  %201 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %202 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Add(%200, %201)\n  %203 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Sqrt(%202)\n  %204 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Div(%197, %203)\n  %205 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Mul(%204, %decoder.transformer.0.skip_c_1.ln.weight)\n  %206 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%205, %decoder.transformer.0.skip_c_1.ln.bias)\n  %207 : Long(3, strides=[1], device=cpu) = onnx::Shape(%206)\n  %208 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %209 : Long(device=cpu) = onnx::Gather[axis=0](%207, %208) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:28:0\n  %211 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%206, %324) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %212 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%211, %decoder.transformer.1.attn.WQ.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %217 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%209)\n  %220 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%325, %217, %326, %327)\n  %221 : Float(1, 50, 8, 32, strides=[12800, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%212, %220) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:29:0\n  %222 : Float(1, 8, 50, 32, strides=[12800, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%221) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:29:0\n  %224 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%206, %328) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %225 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%224, %decoder.transformer.1.attn.WK.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %230 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%209)\n  %233 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%329, %230, %330, %331)\n  %234 : Float(1, 50, 8, 32, strides=[12800, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%225, %233) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:30:0\n  %236 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%206, %332) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %237 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%236, %decoder.transformer.1.attn.WV.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %242 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%209)\n  %245 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%333, %242, %334, %335)\n  %246 : Float(1, 50, 8, 32, strides=[12800, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%237, %245) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %247 : Float(1, 8, 50, 32, strides=[12800, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%246) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:31:0\n  %248 : Float(1, 8, 32, 50, strides=[12800, 32, 1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%234) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %249 : Float(1, 8, 50, 50, strides=[20000, 2500, 50, 1], requires_grad=1, device=cpu) = onnx::MatMul(%222, %248) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:59:0\n  %250 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n  %251 : Float(1, 8, 50, 50, strides=[20000, 2500, 50, 1], requires_grad=1, device=cpu) = onnx::Mul(%249, %250)\n  %252 : Float(1, 8, 50, 50, strides=[20000, 2500, 50, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%251) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:65:0\n  %253 : Float(1, 8, 50, 32, strides=[12800, 1600, 32, 1], requires_grad=1, device=cpu) = onnx::MatMul(%252, %247) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:68:0\n  %254 : Float(1, 50, 8, 32, strides=[12800, 32, 1600, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%253) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:38:0\n  %255 : Long(4, strides=[1], device=cpu) = onnx::Shape(%254)\n  %256 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %257 : Long(device=cpu) = onnx::Gather[axis=0](%255, %256) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %258 : Long(4, strides=[1], device=cpu) = onnx::Shape(%254)\n  %259 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %260 : Long(device=cpu) = onnx::Gather[axis=0](%258, %259) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %262 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%257)\n  %263 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%260)\n  %265 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%262, %263, %336)\n  %266 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape(%254, %265) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_mha.py:39:0\n  %268 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%266, %337) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %269 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%268, %decoder.transformer.1.attn.final_fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %270 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%269, %206) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %271 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%270)\n  %272 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Sub(%270, %271)\n  %273 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %274 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Pow(%272, %273)\n  %275 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%274)\n  %276 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %277 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Add(%275, %276)\n  %278 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Sqrt(%277)\n  %279 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Div(%272, %278)\n  %280 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Mul(%279, %decoder.transformer.1.skip_c_0.ln.weight)\n  %281 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%280, %decoder.transformer.1.skip_c_0.ln.bias)\n  %283 : Float(1, 50, 512, strides=[25600, 512, 1], requires_grad=1, device=cpu) = onnx::MatMul(%281, %338) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %284 : Float(1, 50, 512, strides=[25600, 512, 1], requires_grad=1, device=cpu) = onnx::Add(%283, %decoder.transformer.1.ffn.0.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %285 : Float(1, 50, 512, strides=[25600, 512, 1], requires_grad=1, device=cpu) = onnx::Relu(%284) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1206:0\n  %287 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%285, %339) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %288 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%287, %decoder.transformer.1.ffn.2.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %289 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%288, %281) # g:\\playdict\\recognizer\\train\\decoders\\efficient_transformers\\_layers.py:27:0\n  %290 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%289)\n  %291 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Sub(%289, %290)\n  %292 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %293 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Pow(%291, %292)\n  %294 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1]](%293)\n  %295 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n  %296 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Add(%294, %295)\n  %297 : Float(1, 50, 1, strides=[50, 1, 1], device=cpu) = onnx::Sqrt(%296)\n  %298 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Div(%291, %297)\n  %299 : Float(1, 50, 256, strides=[12800, 256, 1], device=cpu) = onnx::Mul(%298, %decoder.transformer.1.skip_c_1.ln.weight)\n  %300 : Float(1, 50, 256, strides=[12800, 256, 1], requires_grad=1, device=cpu) = onnx::Add(%299, %decoder.transformer.1.skip_c_1.ln.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:2205:0\n  %302 : Float(1, 50, 84, strides=[4200, 84, 1], requires_grad=1, device=cpu) = onnx::MatMul(%300, %340) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %303 : Float(1, 50, 84, strides=[4200, 84, 1], requires_grad=1, device=cpu) = onnx::Add(%302, %decoder.fc.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %y : Long(1, 50, strides=[50, 1], requires_grad=0, device=cpu) = onnx::ArgMax[axis=-1, keepdims=0](%303) # g:\\playdict\\recognizer\\train\\models.py:39:0\n  return (%y)\n\n"]}],"source":["model.load_weights('saved_model/best.pt')\n","\n","model.model.deploy()\n","\n","_ = torch.onnx.export(model.model.cpu(),\n","    train_set[0][0].unsqueeze_(0), \"saved_model/vgg_transformer_ctc_synth.onnx\", verbose=True, opset_version=11, input_names=['x'], output_names=['y'])"]}],"metadata":{"kernelspec":{"name":"python385jvsc74a57bd069ae1faf8d071295817930cd4dd112d51035d617709be1afa53f8ae3e70204c7","display_name":"Python 3.8.5 64-bit ('data_science': conda)"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.5","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}