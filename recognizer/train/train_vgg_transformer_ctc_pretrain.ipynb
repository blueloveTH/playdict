{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:33.511002Z","iopub.status.busy":"2021-03-09T09:44:33.510332Z","iopub.status.idle":"2021-03-09T09:44:33.513336Z","shell.execute_reply":"2021-03-09T09:44:33.512859Z"},"papermill":{"duration":0.022561,"end_time":"2021-03-09T09:44:33.513503","exception":false,"start_time":"2021-03-09T09:44:33.490942","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import os, sys, random, gc\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","sys.path.append('../')\n","\n","from playdict_ocr.tokenization import TokenizerNAT\n","from datasets import PartitionedTrainDataset, TrainDataset, TestDataset"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<PAD><PAD_1><PAD_2>ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz~$%&@0123456789* -([)]\"!,.:;?'"]},"metadata":{},"execution_count":2}],"source":["''.join(TokenizerNAT().i2w)"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:47.311836Z","iopub.status.busy":"2021-03-09T09:44:47.311114Z","iopub.status.idle":"2021-03-09T09:44:47.314953Z","shell.execute_reply":"2021-03-09T09:44:47.31454Z"},"papermill":{"duration":0.027167,"end_time":"2021-03-09T09:44:47.315067","exception":false,"start_time":"2021-03-09T09:44:47.2879","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["class CFG:\n","    max_dec_len=25\n","    size=(144, 32)\n","    epochs, batch_size = 3, 256\n","    max_grad_norm=4\n","    encoder_dim, decoder_dim = 192, 256\n","    use_ctc = False\n","    num_pixels = 36\n","\n","if CFG.use_ctc:\n","    CFG.max_dec_len *= 2\n","\n","tokenizer = TokenizerNAT()"],"execution_count":3,"outputs":[]},{"metadata":{"papermill":{"duration":0.022092,"end_time":"2021-03-09T09:44:52.71725","exception":false,"start_time":"2021-03-09T09:44:52.695158","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# MODEL"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:52.768841Z","iopub.status.busy":"2021-03-09T09:44:52.768043Z","iopub.status.idle":"2021-03-09T09:44:52.77223Z","shell.execute_reply":"2021-03-09T09:44:52.77174Z"},"papermill":{"duration":0.033392,"end_time":"2021-03-09T09:44:52.772345","exception":false,"start_time":"2021-03-09T09:44:52.738953","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import keras4torch as k4t\n","from models import EncoderDecoderModel\n","\n","from encoders.repvgg import RepVGG\n","from decoders.nat import NATDecoder\n","\n","encoder = RepVGG(\n","        num_blocks=[2, 4, 6],\n","        width_multiplier=[0.75, 0.75, 0.75],\n","        use_se=False, in_channels=1, output_channels=CFG.encoder_dim)\n","\n","encoder.load_state_dict(torch.load('saved_model/repvgg_encoder_pretrain.pt'))\n","\n","decoder = NATDecoder(encoder_dim=CFG.encoder_dim,\n","                    decoder_dim=CFG.decoder_dim,\n","                    vocab_size=tokenizer.vocab_size,\n","                    max_dec_len=CFG.max_dec_len,\n","                    num_pixels=CFG.num_pixels)\n","\n","model = EncoderDecoderModel(encoder, decoder)"],"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\n├─RepVGG: 1-1                                      [8, 192, 2, 36]           --\n|    └─RepVGGBlock: 2-1                            [8, 48, 16, 72]           --\n|    |    └─Sequential: 3-1                        [8, 48, 16, 72]           528\n|    |    └─Sequential: 3-2                        [8, 48, 16, 72]           144\n|    |    └─Identity: 3-3                          [8, 48, 16, 72]           --\n|    |    └─ReLU: 3-4                              [8, 48, 16, 72]           --\n|    └─Sequential: 2-2                             [8, 48, 8, 36]            --\n|    |    └─RepVGGBlock: 3-5                       [8, 48, 8, 36]            23,232\n|    |    └─RepVGGBlock: 3-6                       [8, 48, 8, 36]            23,328\n|    └─Sequential: 2-3                             [8, 96, 4, 36]            --\n|    |    └─RepVGGBlock: 3-7                       [8, 96, 4, 36]            46,464\n|    |    └─RepVGGBlock: 3-8                       [8, 96, 4, 36]            92,736\n|    |    └─RepVGGBlock: 3-9                       [8, 96, 4, 36]            92,736\n|    |    └─RepVGGBlock: 3-10                      [8, 96, 4, 36]            92,736\n|    └─Sequential: 2-4                             [8, 192, 2, 36]           --\n|    |    └─RepVGGBlock: 3-11                      [8, 192, 2, 36]           185,088\n|    |    └─RepVGGBlock: 3-12                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-13                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-14                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-15                      [8, 192, 2, 36]           369,792\n|    |    └─RepVGGBlock: 3-16                      [8, 192, 2, 36]           369,792\n|    └─Sequential: 2-5                             [8, 192, 2, 36]           --\n|    |    └─RepVGGBlock: 3-17                      [8, 192, 2, 36]           369,792\n├─NATDecoder: 1-2                                  [8, 25, 84]               --\n|    └─Linear: 2-6                                 [8, 36, 256]              49,408\n|    └─Linear: 2-7                                 [8, 256, 25]              925\n|    └─Sequential: 2-8                             [8, 25, 256]              --\n|    |    └─TransformerEncoderLayer2: 3-18         [8, 25, 256]              527,104\n|    |    └─TransformerEncoderLayer2: 3-19         [8, 25, 256]              527,104\n|    |    └─TransformerEncoderLayer2: 3-20         [8, 25, 256]              527,104\n|    └─Linear: 2-9                                 [8, 25, 84]               21,588\n====================================================================================================\nTotal params: 4,428,977\nTrainable params: 4,428,977\nNon-trainable params: 0\nTotal mult-adds (M): 18.08\n====================================================================================================\nEncoder: 2775744\nDecoder: 1653233\n"]}],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_optimizer import AdaBelief\n","\n","class CombinedOpt(torch.optim.Optimizer):\n","    def __init__(self, model):\n","        super().__init__(model.parameters(), {'lr': float('-inf')})\n","        self.encoder_opt = AdaBelief(\n","            model.encoder.parameters(), lr=2e-3)\n","        self.decoder_opt = torch.optim.Adam(\n","            model.decoder.parameters(), lr=1e-3)\n","\n","    def step(self):\n","        self.encoder_opt.step()\n","        self.decoder_opt.step()\n","\n","opt = CombinedOpt(model)\n","\n","def ce_loss(y_pred, y_true):\n","    y_pred = y_pred.reshape(-1, tokenizer.vocab_size)\n","    y_true = y_true.reshape(-1)\n","    return F.cross_entropy(y_pred, y_true)\n","\n","def acc(y_pred, y_true):\n","    y_pred = y_pred.argmax(-1).cpu().numpy()\n","    y_true = y_true.cpu().numpy()\n","\n","    y_ = [(tokenizer.indices_to_string(i) == tokenizer.indices_to_string(j))\n","            for i,j in zip(y_pred, y_true)]\n","    return torch.tensor(y_, dtype=float).mean()\n","\n","class MyLoopConfig(k4t.configs.TrainerLoopConfig):\n","    def process_batch(self, batch):\n","        *x_batch, y_batch = batch\n","        self.target_lengths = x_batch[1]\n","        return x_batch[:1], y_batch\n","\n","    def prepare_for_optimizer_step(self, model):\n","        torch.nn.utils.clip_grad_norm_(model.model.encoder.parameters(), CFG.max_grad_norm)\n","        torch.nn.utils.clip_grad_norm_(model.model.decoder.parameters(), CFG.max_grad_norm)\n","\n","    def ctc_loss(self, y_pred, y_true):\n","        batch_size = y_pred.size(0)\n","        y_pred = torch.log_softmax(y_pred, dim=-1)      # [bs, max_dec_len*2, vocab_size]\n","        y_pred = y_pred.transpose(0, 1)                 # [max_dec_len*2, bs, vocab_size]\n","        return F.ctc_loss(y_pred, y_true,\n","            input_lengths=torch.full([batch_size], CFG.max_dec_len), target_lengths=self.target_lengths)\n","\n","    def ctc_acc(self, y_pred, y_true):\n","        y_pred = y_pred.argmax(-1).cpu().numpy()\n","        y_true = y_true.cpu().numpy()\n","\n","        y_ = [(tokenizer.indices_to_string_ctc(i) == tokenizer.indices_to_string(j))\n","                for i,j in zip(y_pred, y_true)]\n","\n","        return torch.tensor(y_, dtype=float).mean()\n","\n","model = k4t.Model(model)\n","\n","model.build([1, 32, 144])\n","model.summary()\n","\n","loop = MyLoopConfig()\n","\n","if CFG.use_ctc:\n","    model.compile(optimizer=opt, loss=loop.ctc_loss, metrics=[loop.ctc_acc], loop_config=loop, disable_val_loss=False)\n","else:\n","    model.compile(optimizer=opt, loss=ce_loss, metrics=[acc], loop_config=loop, disable_val_loss=False)\n","\n","model.model.print_params()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["file_list = [f\"../preprocessed/train_data_{i}.pkl\" for i in range(4)]\n","cnt_list = [2000000] * 3 + [1224600]\n","\n","#train_data = pd.read_pickle(\"../preprocessed/synth_0.pkl\")\n","#train_set = TrainDataset(train_data, CFG.max_dec_len, tokenizer, CFG.size)\n","\n","val_data = pd.read_pickle(\"../preprocessed/val_data.pkl\")\n","\n","train_set = PartitionedTrainDataset(file_list, cnt_list, CFG.max_dec_len, tokenizer, CFG.size)\n","val_set = TrainDataset(val_data, CFG.max_dec_len, tokenizer, CFG.size)"]},{"metadata":{"papermill":{"duration":0.021011,"end_time":"2021-03-09T09:44:58.676694","exception":false,"start_time":"2021-03-09T09:44:58.655683","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# Train loop"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:58.736334Z","iopub.status.busy":"2021-03-09T09:44:58.735541Z","iopub.status.idle":"2021-03-09T09:44:58.738849Z","shell.execute_reply":"2021-03-09T09:44:58.738363Z"},"papermill":{"duration":0.041299,"end_time":"2021-03-09T09:44:58.739015","exception":false,"start_time":"2021-03-09T09:44:58.697716","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from keras4torch.callbacks import LRScheduler\n","from torch.optim.lr_scheduler import MultiStepLR\n","from keras4torch.utils.data import RestrictedRandomSampler\n","from keras4torch.callbacks import ModelCheckpoint\n","\n","torch.backends.cudnn.benchmark = True\n","\n","scheduler_1 = LRScheduler(MultiStepLR(opt.encoder_opt, [1, 2], 0.3))\n","scheduler_2 = LRScheduler(MultiStepLR(opt.decoder_opt, [1, 2], 0.3))\n","\n","model.fit(train_set,\n","            validation_data=val_set,\n","            epochs=CFG.epochs,\n","            batch_size=CFG.batch_size,\n","            validation_batch_size=CFG.batch_size*2,\n","            sampler=RestrictedRandomSampler(cnt_list),\n","            callbacks=[scheduler_1, scheduler_2, ModelCheckpoint('saved_model/best.pt', monitor='val_acc')]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["outputPrepend"]},"outputs":[],"source":["model.load_weights('saved_model/best.pt')\n","\n","model.model.deploy()\n","\n","_ = torch.onnx.export(model.model.cpu(),\n","    train_set[0][0].unsqueeze_(0), \"saved_model/vgg_transformer.onnx\", verbose=True, opset_version=11, input_names=['x'], output_names=['y'])"]}],"metadata":{"kernelspec":{"name":"python385jvsc74a57bd069ae1faf8d071295817930cd4dd112d51035d617709be1afa53f8ae3e70204c7","display_name":"Python 3.8.5 64-bit ('data_science': conda)"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.5","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}