{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:33.511002Z","iopub.status.busy":"2021-03-09T09:44:33.510332Z","iopub.status.idle":"2021-03-09T09:44:33.513336Z","shell.execute_reply":"2021-03-09T09:44:33.512859Z"},"papermill":{"duration":0.022561,"end_time":"2021-03-09T09:44:33.513503","exception":false,"start_time":"2021-03-09T09:44:33.490942","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import os, sys, random, gc\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","sys.path.append('../../')\n","sys.path.append('../')\n","\n","from playdict_ocr.tokenization import Tokenizer\n","from datasets import PartitionedTrainDataset, TrainDataset, TestDataset"],"execution_count":1,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:47.311836Z","iopub.status.busy":"2021-03-09T09:44:47.311114Z","iopub.status.idle":"2021-03-09T09:44:47.314953Z","shell.execute_reply":"2021-03-09T09:44:47.31454Z"},"papermill":{"duration":0.027167,"end_time":"2021-03-09T09:44:47.315067","exception":false,"start_time":"2021-03-09T09:44:47.2879","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["class CFG:\n","    max_dec_len=25\n","    size=(144, 32)\n","    epochs, batch_size = 2, 256\n","    max_grad_norm=4\n","    embed_dim, attention_dim = 32, 192\n","    encoder_dim, decoder_dim = 192, 192\n","\n","tokenizer = Tokenizer()"],"execution_count":2,"outputs":[]},{"metadata":{"papermill":{"duration":0.022092,"end_time":"2021-03-09T09:44:52.71725","exception":false,"start_time":"2021-03-09T09:44:52.695158","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# MODEL"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:52.768841Z","iopub.status.busy":"2021-03-09T09:44:52.768043Z","iopub.status.idle":"2021-03-09T09:44:52.77223Z","shell.execute_reply":"2021-03-09T09:44:52.77174Z"},"papermill":{"duration":0.033392,"end_time":"2021-03-09T09:44:52.772345","exception":false,"start_time":"2021-03-09T09:44:52.738953","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["import keras4torch as k4t\n","from models import EncoderDecoderModel\n","\n","from encoders.repvgg import RepVGG\n","from decoders.rnn import DecoderWithAttention\n","\n","encoder = RepVGG(\n","        num_blocks=[2, 4, 6],\n","        width_multiplier=[0.75, 0.75, 0.75],\n","        use_se=False, in_channels=1, output_channels=CFG.encoder_dim)\n","\n","decoder = DecoderWithAttention(attention_dim=CFG.attention_dim,\n","                                    embed_dim=CFG.embed_dim,\n","                                    decoder_dim=CFG.decoder_dim,\n","                                    vocab_size=tokenizer.vocab_size,\n","                                    encoder_dim=CFG.encoder_dim,\n","                                    max_dec_len=CFG.max_dec_len)\n","\n","model = EncoderDecoderModel(encoder, decoder)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder: 2775744\nDecoder: 846421\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n","\n","class CollateWrapper:\n","    # run on cpu\n","    def __call__(self, batch):\n","        src, tgt, tgt_lens = [], [], []\n","        for t in batch:\n","            src.append(t[0])\n","            tgt.append(torch.from_numpy(t[1]))\n","            tgt_lens.append(t[2])\n","\n","        src = torch.stack(src)\n","        tgt = pad_sequence(tgt, batch_first=True, padding_value=0)\n","        tgt_lens = torch.tensor(tgt_lens, dtype=torch.int64)\n","        return src, tgt, tgt_lens, torch.tensor(0)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class MyLoopConfig(k4t.configs.TrainerLoopConfig):\n","    # run on gpu\n","    def process_batch(self, batch):\n","        src, tgt, tgt_lens, _ = batch\n","        if not self.training:\n","            return (src,), tgt\n","\n","        tgt_lens, sort_idx = tgt_lens.sort(dim=0, descending=True)\n","        src, tgt = src[sort_idx], tgt[sort_idx]\n","        return (src, tgt, tgt_lens), tgt\n","\n","    def prepare_for_optimizer_step(self, model):\n","        torch.nn.utils.clip_grad_norm_(model.model.encoder.parameters(), CFG.max_grad_norm)\n","        torch.nn.utils.clip_grad_norm_(model.model.decoder.parameters(), CFG.max_grad_norm)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_optimizer import AdaBelief\n","\n","class CombinedOpt(torch.optim.Optimizer):\n","    def __init__(self, model):\n","        super().__init__(model.parameters(), {'lr': float('-inf')})\n","        self.encoder_opt = AdaBelief(\n","            model.encoder.parameters(), lr=1e-4)\n","        self.decoder_opt = torch.optim.Adam(\n","            model.decoder.parameters(), lr=4e-4)\n","\n","    def step(self):\n","        self.encoder_opt.step()\n","        self.decoder_opt.step()\n","\n","opt = CombinedOpt(model)\n","\n","model = k4t.Model(model)\n","\n","def ce_loss(y_pred, y_true):\n","    y_pred = y_pred.reshape(-1, tokenizer.vocab_size)\n","    y_true = y_true.reshape(-1)\n","    nonzero_indices = torch.nonzero(y_true).view(-1)\n","    return F.cross_entropy(y_pred[nonzero_indices], y_true[nonzero_indices])\n","\n","def acc(y_pred, y_true):\n","    y_pred = y_pred.argmax(-1).cpu().numpy()\n","    y_true = y_true.cpu().numpy()\n","\n","    y_ = [(tokenizer.indices_to_string(i) == tokenizer.indices_to_string(j))\n","            for i,j in zip(y_pred, y_true)]\n","\n","    return torch.tensor(y_, dtype=float).mean()\n","\n","model.compile(optimizer=opt, loss=ce_loss, metrics=[acc], loop_config=MyLoopConfig(), disable_val_loss=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["file_list = [f\"../../preprocessed/synth_{i}.pkl\" for i in range(1)]\n","cnt_list = [1000000] * 1\n","\n","val_data = pd.read_pickle(\"../../preprocessed/val_data.pkl\")\n","\n","train_set = PartitionedTrainDataset(file_list, cnt_list, tokenizer, CFG.size)\n","val_set = TrainDataset(val_data, tokenizer, CFG.size)"]},{"metadata":{"papermill":{"duration":0.021011,"end_time":"2021-03-09T09:44:58.676694","exception":false,"start_time":"2021-03-09T09:44:58.655683","status":"completed"},"tags":[]},"cell_type":"markdown","source":["# Train loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.load_weights('saved_model/best_pretrain.pt')"]},{"metadata":{"execution":{"iopub.execute_input":"2021-03-09T09:44:58.736334Z","iopub.status.busy":"2021-03-09T09:44:58.735541Z","iopub.status.idle":"2021-03-09T09:44:58.738849Z","shell.execute_reply":"2021-03-09T09:44:58.738363Z"},"papermill":{"duration":0.041299,"end_time":"2021-03-09T09:44:58.739015","exception":false,"start_time":"2021-03-09T09:44:58.697716","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from keras4torch.callbacks import LRScheduler\n","import pickle\n","from torch.optim.lr_scheduler import MultiStepLR\n","from keras4torch.utils.data import RestrictedRandomSampler\n","from keras4torch.callbacks import ModelCheckpoint\n","\n","torch.backends.cudnn.benchmark = True\n","\n","scheduler_1 = LRScheduler(MultiStepLR(opt.encoder_opt, [1, 2], 0.3))\n","scheduler_2 = LRScheduler(MultiStepLR(opt.decoder_opt, [1, 2], 0.3))\n","\n","model.fit(train_set,\n","            validation_data=val_set,\n","            epochs=CFG.epochs,\n","            batch_size=CFG.batch_size,\n","            validation_batch_size=CFG.batch_size*2,\n","            collate_fn=CollateWrapper(),\n","            sampler=RestrictedRandomSampler(cnt_list),\n","            callbacks=[scheduler_1, scheduler_2, ModelCheckpoint('saved_model/best.pt', monitor='val_acc')]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stdout","text":["pu), %2322 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2323 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2324 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[192, 192, 192, 192]](%2320) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2325 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2321) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2326 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2322) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2327 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2323) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2328 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2324) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2329 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2325, %2327)\n  %2330 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2326, %2250) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2331 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Add(%2330, %2329) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2332 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2331) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2333 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2328, %2332) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2334 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2317, %decoder.decode_step.cells.1.weight_ih, %decoder.decode_step.cells.1.bias_ih)\n  %2335 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2333, %decoder.decode_step.cells.1.weight_hh, %decoder.decode_step.cells.1.bias_hh) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2336 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Add(%2335, %2334) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2337 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2338 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2339 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2340 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[192, 192, 192, 192]](%2336) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2341 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2337) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2342 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2338) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2343 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2339) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2344 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2340) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2345 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2341, %2343)\n  %2346 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2342, %2331) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2347 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Add(%2346, %2345) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2348 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2347) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2349 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2344, %2348) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2350 : Float(1, 84, strides=[84, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2349, %decoder.fc.weight, %decoder.fc.bias) # ..\\decoders\\rnn.py:119:0\n  %2351 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={23}]()\n  %2352 : Float(*, *, strides=[2100, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%2296, %2351) # ..\\decoders\\rnn.py:120:0\n  %2353 : Long(2, strides=[1], device=cpu) = onnx::Shape(%2352)\n  %2354 : Float(1, 84, strides=[84, 1], requires_grad=0, device=cpu) = onnx::Expand(%2350, %2353) # ..\\decoders\\rnn.py:120:0\n  %2355 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2296)\n  %2356 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %2357 : Long(device=cpu) = onnx::Gather[axis=0](%2355, %2356)\n  %2358 : Long(device=cpu) = onnx::Cast[to=7](%2357)\n  %2359 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %2360 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %2361 : Long(*, device=cpu) = onnx::Range(%2359, %2358, %2360)\n  %2362 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%2351)\n  %2363 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n  %2364 : Long(*, 1, device=cpu) = onnx::Reshape(%2361, %2363)\n  %2365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n  %2366 : Long(1, strides=[1], device=cpu) = onnx::Reshape(%2362, %2365)\n  %2367 : Long(*, 1, device=cpu) = onnx::Add(%2364, %2366)\n  %2368 : Long(2, strides=[1], device=cpu) = onnx::Shape(%2367)\n  %2369 : Long(1, strides=[1], device=cpu) = onnx::Shape(%2368)\n  %2370 : Long(*, device=cpu) = onnx::ConstantOfShape[value={1}](%2369)\n  %2371 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %2372 : Long(*, device=cpu) = onnx::Mul(%2370, %2371)\n  %2373 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%2368, %2372)\n  %2374 : Long(2, strides=[1], device=cpu) = onnx::Where(%2373, %2370, %2368)\n  %2375 : LongTensor(device=cpu) = onnx::Expand(%2364, %2374)\n  %2376 : LongTensor(device=cpu) = onnx::Unsqueeze[axes=[-1]](%2375)\n  %2377 : Long(1, strides=[1], device=cpu) = onnx::Shape(%2368)\n  %2378 : Long(*, device=cpu) = onnx::ConstantOfShape[value={1}](%2377)\n  %2379 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %2380 : Long(*, device=cpu) = onnx::Mul(%2378, %2379)\n  %2381 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%2368, %2380)\n  %2382 : Long(2, strides=[1], device=cpu) = onnx::Where(%2381, %2378, %2368)\n  %2383 : LongTensor(device=cpu) = onnx::Expand(%2366, %2382)\n  %2384 : LongTensor(device=cpu) = onnx::Unsqueeze[axes=[-1]](%2383)\n  %2385 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%2376, %2384)\n  %2386 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2296)\n  %2387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %2388 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n  %2389 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n  %2390 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2386, %2388, %2389, %2387)\n  %2391 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2368, %2390)\n  %2392 : FloatTensor(device=cpu) = onnx::Reshape(%2354, %2391)\n  %2393 : Float(*, *, *, strides=[2100, 84, 1], requires_grad=0, device=cpu) = onnx::ScatterND(%2296, %2385, %2392) # ..\\decoders\\rnn.py:120:0\n  %2394 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::ArgMax[axis=-1, keepdims=0](%2350) # ..\\decoders\\rnn.py:122:0\n  %2395 : Float(1, 32, strides=[32, 1], requires_grad=1, device=cpu) = onnx::Gather(%decoder.embedding.weight, %2394) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1916:0\n  %2396 : Float(192, 192, strides=[1, 192], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.attention.encoder_att.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2397 : Float(1, 36, 192, strides=[6912, 192, 1], requires_grad=1, device=cpu) = onnx::MatMul(%89, %2396) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2398 : Float(1, 36, 192, strides=[6912, 192, 1], requires_grad=1, device=cpu) = onnx::Add(%2397, %decoder.attention.encoder_att.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2399 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2349, %decoder.attention.decoder_att.weight, %decoder.attention.decoder_att.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2400 : Float(1, 1, 192, strides=[192, 192, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[axes=[1]](%2399) # ..\\decoders\\rnn.py:19:0\n  %2401 : Float(1, 36, 192, strides=[6912, 192, 1], requires_grad=1, device=cpu) = onnx::Add(%2398, %2400) # ..\\decoders\\rnn.py:20:0\n  %2402 : Float(1, 36, 192, strides=[6912, 192, 1], requires_grad=1, device=cpu) = onnx::Relu(%2401) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1204:0\n  %2403 : Float(192, 1, strides=[1, 192], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0]](%decoder.attention.full_att.1.weight) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2404 : Float(1, 36, 1, strides=[36, 1, 1], requires_grad=1, device=cpu) = onnx::MatMul(%2402, %2403) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2405 : Float(1, 36, 1, strides=[36, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%2404, %decoder.attention.full_att.1.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2406 : Float(1, 1, 36, strides=[36, 36, 1], device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%2405)\n  %2407 : Float(1, 1, 36, strides=[36, 36, 1], device=cpu) = onnx::Softmax[axis=2](%2406)\n  %2408 : Float(1, 36, 1, strides=[36, 1, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%2407) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1583:0\n  %2409 : Float(1, 36, 192, strides=[6912, 192, 1], requires_grad=1, device=cpu) = onnx::Mul(%89, %2408) # ..\\decoders\\rnn.py:21:0\n  %2410 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::ReduceSum[axes=[1], keepdims=0](%2409) # ..\\decoders\\rnn.py:21:0\n  %2411 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2349, %decoder.fc_gate.0.weight, %decoder.fc_gate.0.bias) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n  %2412 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2411)\n  %2413 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2410, %2412) # ..\\decoders\\rnn.py:112:0\n  %2414 : Float(1, 224, strides=[224, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%2395, %2413) # ..\\decoders\\rnn.py:115:0\n  %2415 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2414, %decoder.decode_step.cells.0.weight_ih, %decoder.decode_step.cells.0.bias_ih)\n  %2416 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2349, %decoder.decode_step.cells.0.weight_hh, %decoder.decode_step.cells.0.bias_hh) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2417 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Add(%2416, %2415) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2418 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2419 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2420 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2421 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[192, 192, 192, 192]](%2417) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2422 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2418) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2423 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2419) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2424 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2420) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2425 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2421) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2426 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2422, %2424)\n  %2427 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2423, %2347) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2428 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Add(%2427, %2426) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2429 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2428) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2430 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2425, %2429) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2431 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2414, %decoder.decode_step.cells.1.weight_ih, %decoder.decode_step.cells.1.bias_ih)\n  %2432 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2430, %decoder.decode_step.cells.1.weight_hh, %decoder.decode_step.cells.1.bias_hh) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2433 : Float(1, 768, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Add(%2432, %2431) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2434 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2435 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2436 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu), %2437 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[192, 192, 192, 192]](%2433) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2438 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2434) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2439 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2435) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2440 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2436) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2441 : Float(1, 192, strides=[768, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%2437) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2442 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2438, %2440)\n  %2443 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2439, %2428) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2444 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Add(%2443, %2442) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2445 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Tanh(%2444) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2446 : Float(1, 192, strides=[192, 1], requires_grad=1, device=cpu) = onnx::Mul(%2441, %2445) # D:\\miniconda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1054:0\n  %2447 : Float(1, 84, strides=[84, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%2446, %decoder.fc.weight, %decoder.fc.bias) # ..\\decoders\\rnn.py:119:0\n  %2448 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={24}]()\n  %2449 : Float(*, *, strides=[2100, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%2393, %2448) # ..\\decoders\\rnn.py:120:0\n  %2450 : Long(2, strides=[1], device=cpu) = onnx::Shape(%2449)\n  %2451 : Float(1, 84, strides=[84, 1], requires_grad=0, device=cpu) = onnx::Expand(%2447, %2450) # ..\\decoders\\rnn.py:120:0\n  %2452 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2393)\n  %2453 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %2454 : Long(device=cpu) = onnx::Gather[axis=0](%2452, %2453)\n  %2455 : Long(device=cpu) = onnx::Cast[to=7](%2454)\n  %2456 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %2457 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %2458 : Long(*, device=cpu) = onnx::Range(%2456, %2455, %2457)\n  %2459 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%2448)\n  %2460 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n  %2461 : Long(*, 1, device=cpu) = onnx::Reshape(%2458, %2460)\n  %2462 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n  %2463 : Long(1, strides=[1], device=cpu) = onnx::Reshape(%2459, %2462)\n  %2464 : Long(*, 1, device=cpu) = onnx::Add(%2461, %2463)\n  %2465 : Long(2, strides=[1], device=cpu) = onnx::Shape(%2464)\n  %2466 : Long(1, strides=[1], device=cpu) = onnx::Shape(%2465)\n  %2467 : Long(*, device=cpu) = onnx::ConstantOfShape[value={1}](%2466)\n  %2468 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %2469 : Long(*, device=cpu) = onnx::Mul(%2467, %2468)\n  %2470 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%2465, %2469)\n  %2471 : Long(2, strides=[1], device=cpu) = onnx::Where(%2470, %2467, %2465)\n  %2472 : LongTensor(device=cpu) = onnx::Expand(%2461, %2471)\n  %2473 : LongTensor(device=cpu) = onnx::Unsqueeze[axes=[-1]](%2472)\n  %2474 : Long(1, strides=[1], device=cpu) = onnx::Shape(%2465)\n  %2475 : Long(*, device=cpu) = onnx::ConstantOfShape[value={1}](%2474)\n  %2476 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %2477 : Long(*, device=cpu) = onnx::Mul(%2475, %2476)\n  %2478 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%2465, %2477)\n  %2479 : Long(2, strides=[1], device=cpu) = onnx::Where(%2478, %2475, %2465)\n  %2480 : LongTensor(device=cpu) = onnx::Expand(%2463, %2479)\n  %2481 : LongTensor(device=cpu) = onnx::Unsqueeze[axes=[-1]](%2480)\n  %2482 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%2473, %2481)\n  %2483 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2393)\n  %2484 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n  %2485 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n  %2486 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n  %2487 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2483, %2485, %2486, %2484)\n  %2488 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2465, %2487)\n  %2489 : FloatTensor(device=cpu) = onnx::Reshape(%2451, %2488)\n  %2490 : Float(*, *, *, requires_grad=0, device=cpu) = onnx::ScatterND(%2393, %2482, %2489)\n  %y : Long(*, *, strides=[25, 1], requires_grad=0, device=cpu) = onnx::ArgMax[axis=-1, keepdims=0](%2490) # g:\\playdict\\recognizer\\train\\backup\\models.py:49:0\n  return (%y)\n\n"]}],"source":["model.load_weights('saved_model/best.pt')\n","\n","model.model.deploy()\n","\n","_ = torch.onnx.export(model.model.cpu(),\n","    torch.randint(0, 256, [1,1,32,144], dtype=torch.uint8), \"saved_model/vgg_lstm.onnx\", verbose=True, opset_version=11, input_names=['x'], output_names=['y'], do_constant_folding=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"name":"python385jvsc74a57bd069ae1faf8d071295817930cd4dd112d51035d617709be1afa53f8ae3e70204c7","display_name":"Python 3.8.5 64-bit ('data_science': conda)"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.5","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}